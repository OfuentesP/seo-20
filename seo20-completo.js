const fs = require('fs');
const path = require('path');
const { generarInformeUnificadoCompleto } = require('./generarInformeUnificadoCompleto');
const generarPDFConHTML = require('./pdf-generator');
const ejecutarScraping = require('./generar-scrapping-funcional');

process.on('unhandledRejection', (reason, promise) => {
  console.error('Unhandled Rejection at:', promise, 'reason:', reason);
});

async function ejecutarLighthouse(url, carpeta) {
  const { default: lighthouse } = await import('lighthouse');
  const chromeLauncher = await import('chrome-launcher');

  const chrome = await chromeLauncher.launch({
    chromeFlags: [
      '--headless',
      '--no-sandbox',
      '--disable-setuid-sandbox',
      '--disable-dev-shm-usage',
      '--disable-gpu',
      '--single-process',
      '--no-zygote'
    ],
    executablePath: '/home/seo_user/.cache/puppeteer/chrome/linux-135.0.7049.84/chrome-linux64/chrome'
  });

  try {
    const result = await lighthouse(url, {
      port: chrome.port, // âœ… Esta lÃ­nea es la CLAVE
      output: 'json',
      logLevel: 'info'
    });

    const outputPath = path.join(carpeta, 'lighthouse.json');
    fs.writeFileSync(outputPath, result.report);
    console.log(`ðŸ“Š Lighthouse guardado en: ${outputPath}`);
  } catch (error) {
    console.error('âŒ Error ejecutando Lighthouse:', error);
  } finally {
    await chrome.kill();
  }
}

(async () => {
  const url = process.argv[2];

  if (!url || !url.startsWith('http')) {
    console.error('âŒ Debes proporcionar una URL vÃ¡lida como argumento.');
    process.exit(1);
  }

  console.log('ðŸ“¥ Iniciando scraping...');
  await ejecutarScraping(url);
  console.log('âœ… Scraping completado.');

  const fecha = new Date().toISOString().split('T')[0];
  const dominio = new URL(url).hostname.replace(/^www\./, '');
  const carpeta = path.join(__dirname, 'resultados', `${fecha}_${dominio}`);
  const scrapingPath = path.join(carpeta, 'scraping.txt');
  let textoScraping = '';

  if (fs.existsSync(scrapingPath)) {
    textoScraping = fs.readFileSync(scrapingPath, 'utf-8').trim();
  }

  await ejecutarLighthouse(url, carpeta);

  const { homeResult } = await generarInformeUnificadoCompleto({
    url,
    textoScraping
  });

  const homeResultHTML = homeResult
    .map(b => `<h3>${b.titulo}</h3>\n${b.contenido}`)
    .join('\n');

  const recomendacionesPath = path.join(carpeta, 'recomendaciones.html');
  const sitemapPath = path.join(carpeta, 'sitemap-analysis.html');
  const urlsPath = path.join(carpeta, 'analisis-por-url.html');
  const erroresPath = path.join(carpeta, 'urls-con-errores.html');

  const recomendacionesHTML = fs.existsSync(recomendacionesPath) ? fs.readFileSync(recomendacionesPath, 'utf-8') : '';
  const sitemapHTML = fs.existsSync(sitemapPath) ? fs.readFileSync(sitemapPath, 'utf-8') : '';
  const urlsPorPaginaHTML = fs.existsSync(urlsPath) ? fs.readFileSync(urlsPath, 'utf-8') : '';
  const erroresHTML = fs.existsSync(erroresPath) ? fs.readFileSync(erroresPath, 'utf-8') : '';

  const informePath = path.join(carpeta, 'informe-seo-final.pdf');
  await generarPDFConHTML({
    sitio: dominio,
    fecha,
    lighthouseScoresHTML: '',
    coreWebVitalsHTML: '',
    homeResultHTML,
    recomendacionesHTML,
    sitemapHTML,
    urlsPorPaginaHTML,
    erroresHTML,
    outputPath: informePath
  });

  const destino = path.join(__dirname, 'resultados', 'informe-seo.pdf');
  fs.copyFileSync(informePath, destino);
  console.log(`ðŸ“Ž Copia del informe disponible en: ${destino}`);
  console.log(`ðŸŽ‰ Informe PDF final generado: ${informePath}`);
})();
